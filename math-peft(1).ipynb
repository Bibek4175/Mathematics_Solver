{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8394123,"sourceType":"datasetVersion","datasetId":4993561}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-13T12:57:58.164768Z","iopub.execute_input":"2024-05-13T12:57:58.165651Z","iopub.status.idle":"2024-05-13T12:57:59.090666Z","shell.execute_reply.started":"2024-05-13T12:57:58.165597Z","shell.execute_reply":"2024-05-13T12:57:59.089624Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/mathsfsdf/kaggle/working/peft-dialogue-summary-training-1715532138/checkpoint-100/adapter_model.safetensors\n/kaggle/input/mathsfsdf/kaggle/working/peft-dialogue-summary-training-1715532138/checkpoint-100/trainer_state.json\n/kaggle/input/mathsfsdf/kaggle/working/peft-dialogue-summary-training-1715532138/checkpoint-100/training_args.bin\n/kaggle/input/mathsfsdf/kaggle/working/peft-dialogue-summary-training-1715532138/checkpoint-100/adapter_config.json\n/kaggle/input/mathsfsdf/kaggle/working/peft-dialogue-summary-training-1715532138/checkpoint-100/README.md\n/kaggle/input/mathsfsdf/kaggle/working/peft-dialogue-summary-training-1715532138/checkpoint-100/scheduler.pt\n/kaggle/input/mathsfsdf/kaggle/working/peft-dialogue-summary-training-1715532138/checkpoint-100/optimizer.pt\n/kaggle/input/mathsfsdf/kaggle/working/peft-dialogue-summary-training-1715532138/checkpoint-100/rng_state.pth\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -q -U bitsandbytes transformers peft accelerate datasets scipy einops evaluate trl rouge_score","metadata":{"execution":{"iopub.status.busy":"2024-05-13T12:57:59.092923Z","iopub.execute_input":"2024-05-13T12:57:59.093456Z","iopub.status.idle":"2024-05-13T12:58:49.153765Z","shell.execute_reply.started":"2024-05-13T12:57:59.093421Z","shell.execute_reply":"2024-05-13T12:58:49.152240Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\nydata-profiling 4.6.4 requires scipy<1.12,>=1.4.1, but you have scipy 1.13.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -q streamlit\n!pip install -U \"transformers==4.40.0\" --upgrade\n!npm install localtunnel\n!pip install pix2text\n!pip install bitsandbytes\n!pip install accelerate","metadata":{"execution":{"iopub.status.busy":"2024-05-13T12:58:49.155833Z","iopub.execute_input":"2024-05-13T12:58:49.156328Z","iopub.status.idle":"2024-05-13T13:00:32.908006Z","shell.execute_reply.started":"2024-05-13T12:58:49.156270Z","shell.execute_reply":"2024-05-13T13:00:32.906705Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting transformers==4.40.0\n  Downloading transformers-4.40.0-py3-none-any.whl.metadata (137 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m550.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0) (2.31.0)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.40.0) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.0) (2024.2.2)\nDownloading transformers-4.40.0-py3-none-any.whl (9.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.40.2\n    Uninstalling transformers-4.40.2:\n      Successfully uninstalled transformers-4.40.2\nSuccessfully installed transformers-4.40.0\n\u001b[K\u001b[?25hm#################\u001b[0m\u001b[100;90m.\u001b[0m] - reify:yargs-parser: \u001b[32;40mhttp\u001b[0m \u001b[35mfetch\u001b[0m GET 200 https://registry.\u001b[0m\u001b[K\nadded 22 packages in 2s\n\n3 packages are looking for funding\n  run `npm fund` for details\n\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m \n\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m New \u001b[33mminor\u001b[39m version of npm available! \u001b[31m10.1.0\u001b[39m -> \u001b[32m10.7.0\u001b[39m\n\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m Changelog: \u001b[36mhttps://github.com/npm/cli/releases/tag/v10.7.0\u001b[39m\n\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m Run \u001b[32mnpm install -g npm@10.7.0\u001b[39m to update!\n\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m \n\u001b[0mCollecting pix2text\n  Downloading pix2text-1.1.0.2-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from pix2text) (8.1.7)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from pix2text) (4.66.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pix2text) (1.26.4)\nRequirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (from pix2text) (4.9.0.80)\nCollecting cnocr>=2.3.0.2 (from cnocr[ort-cpu]>=2.3.0.2->pix2text)\n  Downloading cnocr-2.3.0.2-py3-none-any.whl.metadata (23 kB)\nCollecting cnstd>=1.2.3.6 (from pix2text)\n  Downloading cnstd-1.2.3.6-py3-none-any.whl.metadata (30 kB)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from pix2text) (9.5.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from pix2text) (2.1.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from pix2text) (0.16.2)\nRequirement already satisfied: transformers>=4.37.0 in /opt/conda/lib/python3.10/site-packages (from pix2text) (4.40.0)\nCollecting optimum[onnxruntime] (from pix2text)\n  Downloading optimum-1.19.2-py3-none-any.whl.metadata (19 kB)\nCollecting PyMuPDF (from pix2text)\n  Downloading PyMuPDF-1.24.3-cp310-none-manylinux2014_x86_64.whl.metadata (3.4 kB)\nCollecting pyspellchecker (from pix2text)\n  Downloading pyspellchecker-0.8.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: pytorch-lightning>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text) (2.2.2)\nRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (from cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text) (0.16.6)\nRequirement already satisfied: torchmetrics in /opt/conda/lib/python3.10/site-packages (from cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text) (1.3.2)\nRequirement already satisfied: onnx in /opt/conda/lib/python3.10/site-packages (from cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text) (1.16.0)\nCollecting onnxruntime (from cnocr[ort-cpu]>=2.3.0.2->pix2text)\n  Downloading onnxruntime-1.17.3-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.4 kB)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from cnstd>=1.2.3.6->pix2text) (6.0.1)\nCollecting unidecode (from cnstd>=1.2.3.6->pix2text)\n  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from cnstd>=1.2.3.6->pix2text) (1.13.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from cnstd>=1.2.3.6->pix2text) (2.1.4)\nRequirement already satisfied: shapely in /opt/conda/lib/python3.10/site-packages (from cnstd>=1.2.3.6->pix2text) (1.8.5.post1)\nCollecting Polygon3 (from cnstd>=1.2.3.6->pix2text)\n  Downloading Polygon3-3.0.9.1.tar.gz (39 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: pyclipper in /opt/conda/lib/python3.10/site-packages (from cnstd>=1.2.3.6->pix2text) (1.3.0.post5)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from cnstd>=1.2.3.6->pix2text) (3.7.5)\nRequirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (from cnstd>=1.2.3.6->pix2text) (0.12.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from cnstd>=1.2.3.6->pix2text) (0.22.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->pix2text) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->pix2text) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->pix2text) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->pix2text) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->pix2text) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->pix2text) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision->pix2text) (2.31.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.37.0->pix2text) (21.3)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.37.0->pix2text) (2023.12.25)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.37.0->pix2text) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.37.0->pix2text) (0.4.3)\nCollecting coloredlogs (from optimum[onnxruntime]->pix2text)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from optimum[onnxruntime]->pix2text) (2.19.1)\nRequirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (from optimum[onnxruntime]->pix2text) (0.4.2)\nRequirement already satisfied: protobuf>=3.20.1 in /opt/conda/lib/python3.10/site-packages (from optimum[onnxruntime]->pix2text) (3.20.3)\nCollecting PyMuPDFb==1.24.3 (from PyMuPDF->pix2text)\n  Downloading PyMuPDFb-1.24.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum[onnxruntime]->pix2text) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->optimum[onnxruntime]->pix2text) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum[onnxruntime]->pix2text) (0.3.8)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->optimum[onnxruntime]->pix2text) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->optimum[onnxruntime]->pix2text) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->optimum[onnxruntime]->pix2text) (3.9.1)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime->cnocr[ort-cpu]>=2.3.0.2->pix2text) (23.5.26)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.37.0->pix2text) (3.1.1)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning>=2.0.0->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text) (0.11.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->pix2text) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->pix2text) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->pix2text) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->pix2text) (2024.2.2)\nRequirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]<4.41.0,>=4.26.0->optimum[onnxruntime]->pix2text) (0.2.0)\nCollecting humanfriendly>=9.1 (from coloredlogs->optimum[onnxruntime]->pix2text)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->pix2text) (2.1.3)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->cnstd>=1.2.3.6->pix2text) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->cnstd>=1.2.3.6->pix2text) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->cnstd>=1.2.3.6->pix2text) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->cnstd>=1.2.3.6->pix2text) (1.4.5)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->cnstd>=1.2.3.6->pix2text) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->cnstd>=1.2.3.6->pix2text) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->cnstd>=1.2.3.6->pix2text) (2023.4)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->pix2text) (1.3.0)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text) (3.1.41)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text) (1.45.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text) (0.4.0)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text) (69.0.3)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text) (1.4.4)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text) (1.16.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum[onnxruntime]->pix2text) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum[onnxruntime]->pix2text) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum[onnxruntime]->pix2text) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum[onnxruntime]->pix2text) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum[onnxruntime]->pix2text) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum[onnxruntime]->pix2text) (4.0.3)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text) (4.0.11)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->cnocr>=2.3.0.2->cnocr[ort-cpu]>=2.3.0.2->pix2text) (5.0.1)\nDownloading pix2text-1.1.0.2-py3-none-any.whl (161 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.1/161.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cnocr-2.3.0.2-py3-none-any.whl (222 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.1/222.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cnstd-1.2.3.6-py3-none-any.whl (246 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.5/246.5 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading PyMuPDF-1.24.3-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading PyMuPDFb-1.24.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pyspellchecker-0.8.1-py3-none-any.whl (6.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading onnxruntime-1.17.3-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading optimum-1.19.2-py3-none-any.whl (417 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.0/417.0 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: Polygon3\n  Building wheel for Polygon3 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for Polygon3: filename=Polygon3-3.0.9.1-cp310-cp310-linux_x86_64.whl size=47849 sha256=55cca0b6e79ec73da1117b7b84ae1155d5d370944b9a1b665df6ebcb2e72b0a1\n  Stored in directory: /root/.cache/pip/wheels/d8/b7/f6/b4e24f56a1cc9856dca98cc2fdc3915d7649b39b62f3dbca9e\nSuccessfully built Polygon3\nInstalling collected packages: Polygon3, unidecode, pyspellchecker, PyMuPDFb, humanfriendly, PyMuPDF, coloredlogs, onnxruntime, cnstd, optimum, cnocr, pix2text\nSuccessfully installed Polygon3-3.0.9.1 PyMuPDF-1.24.3 PyMuPDFb-1.24.3 cnocr-2.3.0.2 cnstd-1.2.3.6 coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.17.3 optimum-1.19.2 pix2text-1.1.0.2 pyspellchecker-0.8.1 unidecode-1.3.8\nRequirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.43.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.30.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.22.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\n# disable Weights and Biases\nos.environ['WANDB_DISABLED']=\"true\"","metadata":{"execution":{"iopub.status.busy":"2024-05-12T16:34:50.179757Z","iopub.execute_input":"2024-05-12T16:34:50.180115Z","iopub.status.idle":"2024-05-12T16:34:50.185223Z","shell.execute_reply.started":"2024-05-12T16:34:50.180082Z","shell.execute_reply":"2024-05-12T16:34:50.184216Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    AutoTokenizer,\n    TrainingArguments,\n    Trainer,\n    GenerationConfig\n)\nfrom tqdm import tqdm\nfrom trl import SFTTrainer\nimport torch\nimport time\nimport pandas as pd\nimport numpy as np\nfrom huggingface_hub import interpreter_login\n\ninterpreter_login()","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:00:32.911528Z","iopub.execute_input":"2024-05-13T13:00:32.911869Z","iopub.status.idle":"2024-05-13T13:01:53.943168Z","shell.execute_reply.started":"2024-05-13T13:00:32.911837Z","shell.execute_reply":"2024-05-13T13:01:53.942153Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-05-13 13:00:43.040032: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-13 13:00:43.040146: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-13 13:00:43.161734: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"\n    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n\n    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your token (input will not be visible):  ·····································\nAdd token as git credential? (Y/n)  n\n"},{"name":"stdout","text":"Token is valid (permission: read).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"huggingface_dataset_name = \"microsoft/orca-math-word-problems-200k\"\ndataset = load_dataset(huggingface_dataset_name)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T16:35:35.395746Z","iopub.execute_input":"2024-05-12T16:35:35.396506Z","iopub.status.idle":"2024-05-12T16:35:39.758938Z","shell.execute_reply.started":"2024-05-12T16:35:35.396468Z","shell.execute_reply":"2024-05-12T16:35:39.758192Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/6.91k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3a72d9c400c42c4900afead4ab7b3e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/84.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4470713b92b64998985a06b2ce866ae0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/200035 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f987d6baf9541bba81fb99a4997f37f"}},"metadata":{}}]},{"cell_type":"code","source":"dataset['train'][0]","metadata":{"execution":{"iopub.status.busy":"2024-05-12T16:35:39.760058Z","iopub.execute_input":"2024-05-12T16:35:39.760415Z","iopub.status.idle":"2024-05-12T16:35:39.769324Z","shell.execute_reply.started":"2024-05-12T16:35:39.760388Z","shell.execute_reply":"2024-05-12T16:35:39.768412Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'question': 'Jungkook is the 5th place. Find the number of people who crossed the finish line faster than Jungkook.',\n 'answer': 'If Jungkook is in 5th place, then 4 people crossed the finish line faster than him.'}"},"metadata":{}}]},{"cell_type":"code","source":"compute_dtype = getattr(torch, \"float16\")\nbnb_config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_quant_type='nf4',\n        bnb_4bit_compute_dtype=compute_dtype,\n        bnb_4bit_use_double_quant=False,\n    )","metadata":{"execution":{"iopub.status.busy":"2024-05-12T16:35:39.770926Z","iopub.execute_input":"2024-05-12T16:35:39.771270Z","iopub.status.idle":"2024-05-12T16:35:40.087785Z","shell.execute_reply.started":"2024-05-12T16:35:39.771238Z","shell.execute_reply":"2024-05-12T16:35:40.086691Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model_name = \"unsloth/llama-3-8b-Instruct-bnb-4bit\"\ndevice_map = {\"\": 0}\noriginal_model = AutoModelForCausalLM.from_pretrained(model_name, \n                                                      device_map=device_map,\n                                                      quantization_config=bnb_config,\n                                                      trust_remote_code=True,\n                                                      use_auth_token=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-12T16:35:40.089068Z","iopub.execute_input":"2024-05-12T16:35:40.089415Z","iopub.status.idle":"2024-05-12T16:36:08.346954Z","shell.execute_reply.started":"2024-05-12T16:35:40.089386Z","shell.execute_reply":"2024-05-12T16:36:08.346180Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:468: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"552ad43a2ce548eeba176dd18371fc7c"}},"metadata":{}},{"name":"stderr","text":"Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n/opt/conda/lib/python3.10/site-packages/transformers/quantizers/auto.py:159: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n  warnings.warn(warning_msg)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2af92ca7a6e742d3bdf339d32b4272e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/131 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1ee67358b4f4fbc8d34a3537beb8dc3"}},"metadata":{}}]},{"cell_type":"code","source":"#Tokenization\ntokenizer = AutoTokenizer.from_pretrained(model_name,trust_remote_code=True,padding_side=\"left\",add_eos_token=True,add_bos_token=True,use_fast=False)\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2024-05-12T16:36:08.349933Z","iopub.execute_input":"2024-05-12T16:36:08.350249Z","iopub.status.idle":"2024-05-12T16:36:10.305593Z","shell.execute_reply.started":"2024-05-12T16:36:08.350221Z","shell.execute_reply":"2024-05-12T16:36:10.304658Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/51.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3e908cde0b34066a37349840cf57191"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9900bb67f8e94f5eb5e0f1cbcbd1fcc7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/464 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9743113311cf4c5f8e587d497a3fbab0"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:01:53.944433Z","iopub.execute_input":"2024-05-13T13:01:53.945202Z","iopub.status.idle":"2024-05-13T13:01:53.950483Z","shell.execute_reply.started":"2024-05-13T13:01:53.945167Z","shell.execute_reply":"2024-05-13T13:01:53.949282Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def create_prompt_formats(sample):\n    \"\"\"\n    Format various fields of the sample ('instruction','output')\n    Then concatenate them using two newline characters \n    :param sample: Sample dictionnary\n    \"\"\"\n    INTRO_BLURB = \"Below is an instruction that describes a mathematical task. Complete the mathematical task step by step\"\n    INSTRUCTION_KEY = \"### Instruct: Carry out the mathematical task step by step showing latex at each step in inline math\"\n    RESPONSE_KEY = \"### Output:\"\n    END_KEY = \"### End\"\n    \n    blurb = f\"\\n{INTRO_BLURB}\"\n    instruction = f\"{INSTRUCTION_KEY}\"\n    input_context = f\"{sample['question']}\" if sample[\"question\"] else None\n    response = f\"{RESPONSE_KEY}\\n{sample['answer']}\"\n    end = f\"{END_KEY}\"\n    \n    parts = [part for part in [blurb, instruction, input_context, response, end] if part]\n\n    formatted_prompt = \"\\n\\n\".join(parts)\n    sample[\"text\"] = formatted_prompt\n\n    return sample","metadata":{"execution":{"iopub.status.busy":"2024-05-12T16:36:12.645983Z","iopub.execute_input":"2024-05-12T16:36:12.646390Z","iopub.status.idle":"2024-05-12T16:36:12.655449Z","shell.execute_reply.started":"2024-05-12T16:36:12.646351Z","shell.execute_reply":"2024-05-12T16:36:12.654539Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from transformers import set_seed\nseed = 42\nset_seed(seed)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T16:38:30.528199Z","iopub.execute_input":"2024-05-12T16:38:30.528618Z","iopub.status.idle":"2024-05-12T16:38:30.535210Z","shell.execute_reply.started":"2024-05-12T16:38:30.528588Z","shell.execute_reply":"2024-05-12T16:38:30.534213Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from functools import partial\n\ndef get_max_length(model):\n    conf = model.config\n    max_length = None\n    for length_setting in [\"n_positions\", \"max_position_embeddings\", \"seq_length\"]:\n        max_length = getattr(model.config, length_setting, None)\n        if max_length:\n            print(f\"Found max lenth: {max_length}\")\n            break\n    if not max_length:\n        max_length = 1024\n        print(f\"Using default max length: {max_length}\")\n    return max_length\n\n\ndef preprocess_batch(batch, tokenizer, max_length):\n    \"\"\"\n    Tokenizing a batch\n    \"\"\"\n    return tokenizer(\n        batch[\"text\"],\n        max_length=max_length,\n        truncation=True,\n    )\n\ndef preprocess_dataset(tokenizer: AutoTokenizer, max_length: int,seed, dataset):\n    \"\"\"Format & tokenize it so it is ready for training\n    :param tokenizer (AutoTokenizer): Model Tokenizer\n    :param max_length (int): Maximum number of tokens to emit from tokenizer\n    \"\"\"\n        # Add prompt to each sample\n    print(\"Preprocessing dataset...\")\n    dataset = dataset.map(create_prompt_formats)#, batched=True)\n\n    \n    # Apply preprocessing to each batch of the dataset & and remove 'instruction', 'context', 'response', 'category' fields\n    _preprocessing_function = partial(preprocess_batch, max_length=max_length, tokenizer=tokenizer)\n    dataset = dataset.map(\n        _preprocessing_function,\n        batched=True,\n    )\n\n    # Filter out samples that have input_ids exceeding max_length\n    dataset = dataset.filter(lambda sample: len(sample[\"input_ids\"]) < max_length)\n    \n    # Shuffle dataset\n    dataset = dataset.shuffle(seed=seed)\n\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2024-05-12T16:38:47.083892Z","iopub.execute_input":"2024-05-12T16:38:47.084357Z","iopub.status.idle":"2024-05-12T16:38:47.094168Z","shell.execute_reply.started":"2024-05-12T16:38:47.084320Z","shell.execute_reply":"2024-05-12T16:38:47.093180Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"## Pre-process dataset\nmax_length = get_max_length(original_model)\nprint(max_length)\n\ntrain_dataset = preprocess_dataset(tokenizer, max_length,seed, dataset['train'])\n","metadata":{"execution":{"iopub.status.busy":"2024-05-12T16:38:47.096933Z","iopub.execute_input":"2024-05-12T16:38:47.097263Z","iopub.status.idle":"2024-05-12T16:42:18.111073Z","shell.execute_reply.started":"2024-05-12T16:38:47.097235Z","shell.execute_reply":"2024-05-12T16:42:18.110284Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Found max lenth: 8192\n8192\nPreprocessing dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/200035 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b5da1739a8745a4bcf9bf83a1940ccd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/200035 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfff5e4caf6c497694630e6f22b4269f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/200035 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b87d0ce4bf0f4b4a9d31cc1aabee86a5"}},"metadata":{}}]},{"cell_type":"code","source":"# 2 - Using the prepare_model_for_kbit_training method from PEFT\n# Preparing the Model for QLoRA\noriginal_model = prepare_model_for_kbit_training(original_model)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T16:42:18.112915Z","iopub.execute_input":"2024-05-12T16:42:18.113243Z","iopub.status.idle":"2024-05-12T16:42:18.147579Z","shell.execute_reply.started":"2024-05-12T16:42:18.113216Z","shell.execute_reply":"2024-05-12T16:42:18.146663Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n\nconfig = LoraConfig(\n    r=32, #Rank\n    lora_alpha=32,\n    target_modules=[\n        'q_proj',\n        'v_proj',\n        \n    ],\n    bias=\"none\",\n    lora_dropout=0.05,  # Conventional\n    task_type=\"CAUSAL_LM\",\n)\n\n# 1 - Enabling gradient checkpointing to reduce memory usage during fine-tuning\noriginal_model.gradient_checkpointing_enable()\n\npeft_model = get_peft_model(original_model, config)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T16:42:18.148758Z","iopub.execute_input":"2024-05-12T16:42:18.149107Z","iopub.status.idle":"2024-05-12T16:42:18.427840Z","shell.execute_reply.started":"2024-05-12T16:42:18.149074Z","shell.execute_reply":"2024-05-12T16:42:18.426743Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"peft_model.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2024-05-12T16:42:18.429889Z","iopub.execute_input":"2024-05-12T16:42:18.430235Z","iopub.status.idle":"2024-05-12T16:42:18.439282Z","shell.execute_reply.started":"2024-05-12T16:42:18.430206Z","shell.execute_reply":"2024-05-12T16:42:18.438440Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"trainable params: 13,631,488 || all params: 8,043,892,736 || trainable%: 0.16946382115456393\n","output_type":"stream"}]},{"cell_type":"code","source":"output_dir = f'./peft-dialogue-summary-training-{str(int(time.time()))}'\nimport transformers\n\npeft_training_args = TrainingArguments(\n    output_dir = output_dir,\n    warmup_steps=1,\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=4,\n    max_steps=100,\n    learning_rate=2e-4,\n    optim=\"paged_adamw_8bit\",\n    logging_steps=25,\n    logging_dir=\"./logs\",\n    save_strategy=\"steps\",\n    save_steps=25,\n \n    do_eval=False,\n    gradient_checkpointing=True,\n    report_to=\"none\",\n    overwrite_output_dir = 'True',\n    group_by_length=True,\n)\n\npeft_model.config.use_cache = False\n\npeft_trainer = transformers.Trainer(\n    model=peft_model,\n    train_dataset=train_dataset,\n    args=peft_training_args,\n    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T16:42:18.440413Z","iopub.execute_input":"2024-05-12T16:42:18.440743Z","iopub.status.idle":"2024-05-12T16:42:18.478255Z","shell.execute_reply.started":"2024-05-12T16:42:18.440711Z","shell.execute_reply":"2024-05-12T16:42:18.477371Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"max_steps is given, it will override any value given in num_train_epochs\n","output_type":"stream"}]},{"cell_type":"code","source":"peft_trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-05-12T16:42:18.479233Z","iopub.execute_input":"2024-05-12T16:42:18.479485Z","iopub.status.idle":"2024-05-12T17:06:39.241358Z","shell.execute_reply.started":"2024-05-12T16:42:18.479461Z","shell.execute_reply":"2024-05-12T17:06:39.240420Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [100/100 21:54, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>25</td>\n      <td>0.726700</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.662300</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.560100</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.592100</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=100, training_loss=0.6352896976470948, metrics={'train_runtime': 1346.5586, 'train_samples_per_second': 0.297, 'train_steps_per_second': 0.074, 'total_flos': 6566812209930240.0, 'train_loss': 0.6352896976470948, 'epoch': 0.001999650061239283})"},"metadata":{}}]},{"cell_type":"code","source":"!pip install bitsandbytes\n","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:01:53.951863Z","iopub.execute_input":"2024-05-13T13:01:53.952254Z","iopub.status.idle":"2024-05-13T13:02:08.674184Z","shell.execute_reply.started":"2024-05-13T13:01:53.952221Z","shell.execute_reply":"2024-05-13T13:02:08.673080Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.43.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\ndevice_map = {\"\": 0}\ncompute_dtype = getattr(torch, \"float16\")\n\nbnb_config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_quant_type='nf4',\n        bnb_4bit_compute_dtype=compute_dtype,\n        bnb_4bit_use_double_quant=False,\n    )\n\nbase_model_id = \"unsloth/llama-3-8b-Instruct-bnb-4bit\"\nbase_model = AutoModelForCausalLM.from_pretrained(base_model_id, \n                                                      device_map=device_map,\n                                                      quantization_config=bnb_config,\n                                                      trust_remote_code=True,\n                                                      use_auth_token=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T03:57:06.398362Z","iopub.execute_input":"2024-05-13T03:57:06.398858Z","iopub.status.idle":"2024-05-13T03:57:30.129692Z","shell.execute_reply.started":"2024-05-13T03:57:06.398820Z","shell.execute_reply":"2024-05-13T03:57:30.128848Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:468: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c6392aaa87245f3a6fd27da2038fb88"}},"metadata":{}},{"name":"stderr","text":"Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n/opt/conda/lib/python3.10/site-packages/transformers/quantizers/auto.py:159: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n  warnings.warn(warning_msg)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f939113859f4aa198992e31e6511969"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/131 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8797fb00bc64f5c961bc3e8ebdaf63f"}},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install onnxruntime-gpu","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:02:08.675842Z","iopub.execute_input":"2024-05-13T13:02:08.676225Z","iopub.status.idle":"2024-05-13T13:02:31.969301Z","shell.execute_reply.started":"2024-05-13T13:02:08.676190Z","shell.execute_reply":"2024-05-13T13:02:31.968076Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Collecting onnxruntime-gpu\n  Downloading onnxruntime_gpu-1.17.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (4.3 kB)\nRequirement already satisfied: coloredlogs in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (15.0.1)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (23.5.26)\nRequirement already satisfied: numpy>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (1.26.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (21.3)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (3.20.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu) (1.12)\nRequirement already satisfied: humanfriendly>=9.1 in /opt/conda/lib/python3.10/site-packages (from coloredlogs->onnxruntime-gpu) (10.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->onnxruntime-gpu) (3.1.1)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime-gpu) (1.3.0)\nDownloading onnxruntime_gpu-1.17.1-cp310-cp310-manylinux_2_28_x86_64.whl (192.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.1/192.1 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: onnxruntime-gpu\nSuccessfully installed onnxruntime-gpu-1.17.1\n","output_type":"stream"}]},{"cell_type":"code","source":"%%writefile app.py\nimport streamlit as st\nfrom PIL import Image\nimport numpy as np\nfrom pix2text import Pix2Text\nimport urllib\nfrom io import BytesIO\nimport transformers\nimport torch\nimport accelerate\nimport bitsandbytes\nfrom peft import PeftModel\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    AutoTokenizer,\n    TrainingArguments,\n    Trainer,\n    GenerationConfig\n)\nfrom tqdm import tqdm\nfrom trl import SFTTrainer\n\nimport time\nimport pandas as pd\nimport numpy as np\ncompute_dtype = getattr(torch, \"float16\")\nbnb_config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_quant_type='nf4',\n        bnb_4bit_compute_dtype=compute_dtype,\n        bnb_4bit_use_double_quant=False,\n    )\ndevice_map = {\"\": 0}\nbase_model_id = \"unsloth/llama-3-8b-Instruct-bnb-4bit\"\nbase_model = AutoModelForCausalLM.from_pretrained(base_model_id, \n                                                      device_map=device_map,\n                                                      quantization_config=bnb_config,\n                                                      trust_remote_code=True,\n                                                      use_auth_token=True)\n\np2t = Pix2Text.from_config()\nft_model = PeftModel.from_pretrained(base_model, \"/kaggle/input/mathsfsdf/kaggle/working/peft-dialogue-summary-training-1715532138/checkpoint-100\",torch_dtype=torch.float16,is_trainable=False)\n\ntokenizer = AutoTokenizer.from_pretrained(base_model_id,trust_remote_code=True,padding_side=\"left\",add_eos_token=True,add_bos_token=True,use_fast=False)\ntokenizer.pad_token = tokenizer.eos_token\n\npipeline = transformers.pipeline(\n    \"text-generation\",\n    model=ft_model,\n    tokenizer=tokenizer,\n    model_kwargs={\n        \"torch_dtype\": torch.float16,\n        \"quantization_config\": {\"load_in_4bit\": True},\n        \"low_cpu_mem_usage\": True,\n    },\n)\n\n# Title\nst.title(\"Solve your Problem Step by Step.\")\n\n# Description with website link\nst.write(\"\"\"\nThe model is built using Pix2Text and Llama3 with the help of Unsloth. Pix2Text converts the image into text and LaTeX code, while Llama3 with a prompt tries to solve your problem step by step.Model is finetuned using PEFT\nKeep in mind that the model can sometimes generate incorrect answers, so it's advisable to verify the solutions. However, the model can provide useful insights into solving your problem.\n\"\"\")\n\n# Prompt for image upload\nst.write(\"Upload your doubt problem in image format\")\n\n# Create a file uploader\nuploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"jpeg\", \"png\"])\n\nif uploaded_file is not None:\n    # Open the image using PIL\n    img = Image.open(uploaded_file)\n\n    # Run the image through the model\n    math = p2t.recognize_text_formula(img)\n\n    st.write(\"Problem:\")\n    st.write(math)\n\n    messages = [\n        {\"role\": \"system\", \"content\": f\"\"\"You are a helpful math teacher. Your task is to help answer a question given in a document.Understand the given text and {math} problem\"\"\"},\n        {\"role\": \"user\", \"content\": \"\"\"Solve this problem step by step in latex. Write the mathematics using the format of inline math.\n        Example:\n        Q:(9-3)/8 + 5\n        A: First calulate (9-3)=6 \n           Then 6/8 = 0.75 \n           Finally 0.75 + 5 = 5.75\n\n         Q:Roger has 5 tennis ball. He buys 2 more cans of ball. Each can has 3 ball. How many total ball does he have\"?\n         A: first roger has 5 balls. then he buys 2 cans. Each can has 3 ball so 3 *2 = 6 and Finally 6 + 5 =11  \n        \"\"\"},\n    ]\n\n    prompt = pipeline.tokenizer.apply_chat_template(\n            messages,\n            tokenize=False,\n            add_generation_prompt=True\n    )\n\n    terminators = [\n        pipeline.tokenizer.eos_token_id,\n        pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n    ]\n\n    outputs = pipeline(\n        prompt,\n        max_new_tokens=4000,\n        eos_token_id=terminators,\n        do_sample=True,\n        temperature=0.6,\n        top_p=0.9,\n    )\n\n    output = outputs[0][\"generated_text\"][len(prompt):]\n    #output = math\n\n    # Display the output\n    st.write(\"Step by Step Solution:\")\n    st.write(output)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:02:31.971318Z","iopub.execute_input":"2024-05-13T13:02:31.971684Z","iopub.status.idle":"2024-05-13T13:02:31.982445Z","shell.execute_reply.started":"2024-05-13T13:02:31.971651Z","shell.execute_reply":"2024-05-13T13:02:31.981425Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Writing app.py\n","output_type":"stream"}]},{"cell_type":"code","source":"import urllib\n\n\nprint(\"Password/Enpoint IP for localtunnel is:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))\n\n     \n","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:02:31.983827Z","iopub.execute_input":"2024-05-13T13:02:31.984268Z","iopub.status.idle":"2024-05-13T13:02:32.074429Z","shell.execute_reply.started":"2024-05-13T13:02:31.984238Z","shell.execute_reply":"2024-05-13T13:02:32.073352Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Password/Enpoint IP for localtunnel is: 35.231.143.18\n","output_type":"stream"}]},{"cell_type":"code","source":"!streamlit run app.py &>/logs.txt & npx localtunnel --port 8501","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:02:32.078736Z","iopub.execute_input":"2024-05-13T13:02:32.079093Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"your url is: https://rare-rabbits-move.loca.lt\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:59:29.957300Z","iopub.execute_input":"2024-05-12T17:59:29.958220Z","iopub.status.idle":"2024-05-12T17:59:35.118452Z","shell.execute_reply.started":"2024-05-12T17:59:29.958175Z","shell.execute_reply":"2024-05-12T17:59:35.117339Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"  adding: kaggle/working/peft-dialogue-summary-training-1715532138/checkpoint-100/ (stored 0%)\n  adding: kaggle/working/peft-dialogue-summary-training-1715532138/checkpoint-100/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/peft-dialogue-summary-training-1715532138/checkpoint-100/adapter_config.json (deflated 50%)\n  adding: kaggle/working/peft-dialogue-summary-training-1715532138/checkpoint-100/scheduler.pt (deflated 57%)\n  adding: kaggle/working/peft-dialogue-summary-training-1715532138/checkpoint-100/README.md (deflated 66%)\n  adding: kaggle/working/peft-dialogue-summary-training-1715532138/checkpoint-100/trainer_state.json (deflated 61%)\n  adding: kaggle/working/peft-dialogue-summary-training-1715532138/checkpoint-100/optimizer.pt (deflated 20%)\n  adding: kaggle/working/peft-dialogue-summary-training-1715532138/checkpoint-100/training_args.bin (deflated 51%)\n  adding: kaggle/working/peft-dialogue-summary-training-1715532138/checkpoint-100/rng_state.pth (deflated 25%)\n","output_type":"stream"}]},{"cell_type":"code","source":"!unzip /kaggle/working/file.zip","metadata":{"execution":{"iopub.status.busy":"2024-05-12T18:33:53.806575Z","iopub.execute_input":"2024-05-12T18:33:53.807508Z","iopub.status.idle":"2024-05-12T18:33:54.779967Z","shell.execute_reply.started":"2024-05-12T18:33:53.807470Z","shell.execute_reply":"2024-05-12T18:33:54.778511Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"unzip:  cannot find or open /kaggle/working/file.zip, /kaggle/working/file.zip.zip or /kaggle/working/file.zip.ZIP.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}}]}